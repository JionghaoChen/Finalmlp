INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2024-12-28 19:13:52 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5699 [22.1 s]	dev=(AUC@All:0.7812,LOG_LOSS@All:0.5609) [1.5 s] *
INFO:root:Epoch 2     loss=0.5313 [14.9 s]	dev=(AUC@All:0.7837,LOG_LOSS@All:0.5571) [0.6 s] *
INFO:root:Epoch 3     loss=0.5203 [14.9 s]	dev=(AUC@All:0.7819,LOG_LOSS@All:0.5908) [0.8 s]
INFO:root:Epoch 4     loss=0.5137 [15.4 s]	dev=(AUC@All:0.7805,LOG_LOSS@All:0.5808) [0.6 s]
INFO:root:Epoch 5     loss=0.5088 [15.4 s]	dev=(AUC@All:0.7749,LOG_LOSS@All:0.5681) [0.6 s]
INFO:root:Epoch 6     loss=0.5031 [15.1 s]	dev=(AUC@All:0.7697,LOG_LOSS@All:0.5966) [0.6 s]
INFO:root:Epoch 7     loss=0.4971 [15.6 s]	dev=(AUC@All:0.7737,LOG_LOSS@All:0.5848) [0.6 s]
INFO:root:Epoch 8     loss=0.4908 [15.4 s]	dev=(AUC@All:0.7733,LOG_LOSS@All:0.5979) [1.0 s]
INFO:root:Epoch 9     loss=0.4850 [15.3 s]	dev=(AUC@All:0.7741,LOG_LOSS@All:0.5925) [0.8 s]
INFO:root:Epoch 10    loss=0.4793 [15.1 s]	dev=(AUC@All:0.7777,LOG_LOSS@All:0.5835) [0.6 s]
INFO:root:Epoch 11    loss=0.4742 [15.8 s]	dev=(AUC@All:0.7638,LOG_LOSS@All:0.6153) [0.6 s]
INFO:root:Epoch 12    loss=0.4686 [15.0 s]	dev=(AUC@All:0.7642,LOG_LOSS@All:0.6297) [0.8 s]
INFO:root:Epoch 13    loss=0.4637 [15.5 s]	dev=(AUC@All:0.7746,LOG_LOSS@All:0.5900) [0.6 s]
INFO:root:Epoch 14    loss=0.4585 [15.5 s]	dev=(AUC@All:0.7686,LOG_LOSS@All:0.6133) [1.0 s]
INFO:root:Epoch 15    loss=0.4531 [15.0 s]	dev=(AUC@All:0.7708,LOG_LOSS@All:0.6052) [0.6 s]
INFO:root:Epoch 16    loss=0.4482 [15.7 s]	dev=(AUC@All:0.7646,LOG_LOSS@All:0.6109) [0.6 s]
INFO:root:Early stop at 16 based on dev result.
INFO:root:
Best Iter(dev)=    2	 dev=(AUC@All:0.7837,LOG_LOSS@All:0.5571) [263.7 s] 
INFO:root:Load model from ../model/FinalMLPCTR/FinalMLPCTR__ML_1MCTR_context101__0__lr=0.002__l2=1e-06__emb_size=64__loss_n=BCE__use_fs=1.pt
INFO:root:
Dev  After Training: (AUC@All:0.7837,LOG_LOSS@All:0.5571)
INFO:root:
Test After Training: (AUC@All:0.7782,LOG_LOSS@All:0.5604)
INFO:root:Saving CTR prediction results to: ../log/FinalMLPCTR/FinalMLPCTR__ML_1MCTR_context101__0__lr=0/rec-FinalMLPCTR-dev.csv
INFO:root:dev Prediction results saved!
INFO:root:Saving CTR prediction results to: ../log/FinalMLPCTR/FinalMLPCTR__ML_1MCTR_context101__0__lr=0/rec-FinalMLPCTR-test.csv
INFO:root:test Prediction results saved!
INFO:root:
--------------------------------------------- END: 2024-12-28 19:18:30 ---------------------------------------------
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 00:01:28 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5685 [85.7 s]	dev=(AUC@All:0.7784,LOG_LOSS@All:0.5633) [1.0 s] *
INFO:root:Epoch 2     loss=0.5317 [288.1 s]	dev=(AUC@All:0.7759,LOG_LOSS@All:0.5834) [2.0 s]
INFO:root:Epoch 3     loss=0.5208 [470.7 s]	dev=(AUC@All:0.7812,LOG_LOSS@All:0.5982) [2.5 s] *
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:05:16 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:07:48 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5685 [57.2 s]	dev=(AUC@All:0.7784,LOG_LOSS@All:0.5633) [0.9 s] *
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:13:08 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:14:55 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:17:45 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:27:46 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:53:34 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:58:11 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 08:59:58 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 09:05:23 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=0.5685 [53.5 s]	dev=(AUC@All:0.7784,LOG_LOSS@All:0.5633) [0.9 s] *
INFO:root:Epoch 2     loss=0.5317 [273.0 s]	dev=(AUC@All:0.7759,LOG_LOSS@All:0.5834) [2.0 s]
INFO:root:Epoch 3     loss=0.5208 [459.3 s]	dev=(AUC@All:0.7812,LOG_LOSS@All:0.5982) [1.9 s] *
INFO:root:Epoch 4     loss=0.5136 [454.5 s]	dev=(AUC@All:0.7741,LOG_LOSS@All:0.5736) [1.8 s]
INFO:root:Epoch 5     loss=0.5084 [435.5 s]	dev=(AUC@All:0.7738,LOG_LOSS@All:0.5703) [2.0 s]
INFO:root:Epoch 6     loss=0.5026 [404.6 s]	dev=(AUC@All:0.7646,LOG_LOSS@All:0.5877) [1.6 s]
INFO:root:Epoch 7     loss=0.4964 [386.7 s]	dev=(AUC@All:0.7743,LOG_LOSS@All:0.5862) [1.7 s]
INFO:root:Epoch 8     loss=0.4908 [373.7 s]	dev=(AUC@All:0.7737,LOG_LOSS@All:0.6277) [1.7 s]
INFO:root:Epoch 9     loss=0.4856 [368.7 s]	dev=(AUC@All:0.7769,LOG_LOSS@All:0.5904) [1.6 s]
INFO:root:Epoch 10    loss=0.4808 [370.8 s]	dev=(AUC@All:0.7697,LOG_LOSS@All:0.5897) [1.5 s]
INFO:root:Epoch 11    loss=0.4764 [383.8 s]	dev=(AUC@All:0.7668,LOG_LOSS@All:0.6538) [2.9 s]
INFO:root:Epoch 12    loss=0.4715 [380.6 s]	dev=(AUC@All:0.7705,LOG_LOSS@All:0.6019) [1.7 s]
INFO:root:Epoch 13    loss=0.4669 [382.2 s]	dev=(AUC@All:0.7725,LOG_LOSS@All:0.5898) [1.7 s]
INFO:root:Epoch 14    loss=0.4626 [386.1 s]	dev=(AUC@All:0.7756,LOG_LOSS@All:0.5865) [1.5 s]
INFO:root:Epoch 15    loss=0.4580 [388.4 s]	dev=(AUC@All:0.7685,LOG_LOSS@All:0.6069) [1.7 s]
INFO:root:Epoch 16    loss=0.4531 [395.1 s]	dev=(AUC@All:0.7648,LOG_LOSS@All:0.6254) [1.5 s]
INFO:root:Epoch 17    loss=0.4482 [395.0 s]	dev=(AUC@All:0.7576,LOG_LOSS@All:0.6476) [1.7 s]
INFO:root:Early stop at 17 based on dev result.
INFO:root:
Best Iter(dev)=    3	 dev=(AUC@All:0.7812,LOG_LOSS@All:0.5982) [6321.1 s] 
INFO:root:Load model from ../model/FinalMLPCTR/FinalMLPCTR__ML_1MCTR_context101__0__lr=0.002__l2=1e-06__emb_size=64__loss_n=BCE__use_fs=1.pt
INFO:root:
Dev  After Training: (AUC@All:0.7812,LOG_LOSS@All:0.5982)
INFO:root:
Test After Training: (AUC@All:0.7840,LOG_LOSS@All:0.5680)
INFO:root:Saving CTR prediction results to: ../log/FinalMLPCTR/FinalMLPCTR__ML_1MCTR_context101__0__lr=0/rec-FinalMLPCTR-dev.csv
INFO:root:dev Prediction results saved!
INFO:root:Saving CTR prediction results to: ../log/FinalMLPCTR/FinalMLPCTR__ML_1MCTR_context101__0__lr=0/rec-FinalMLPCTR-test.csv
INFO:root:test Prediction results saved!
INFO:root:
--------------------------------------------- END: 2025-01-02 10:51:01 ---------------------------------------------
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 11:00:53 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 11:07:02 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 11:09:38 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 11:11:42 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
INFO:root:Namespace(model_name='FinalMLP', model_mode='CTR')
INFO:root:--------------------------------------------- BEGIN: 2025-01-02 11:14:36 ---------------------------------------------
INFO:root:
===================================================
 Arguments                  | Values               
===================================================
 batch_size                 | 1024                
 data_appendix              | _context101         
 dataset                    | ML_1MCTR            
 dropout                    | 0                   
 early_stop                 | 15                  
 emb_size                   | 64                  
 epoch                      | 200                 
 eval_batch_size            | 256                 
 fs1_context                | c_hour_c,c_weekda...
 fs2_context                | i_genre_c,i_title_c 
 fs_hidden_units            | [256,64]            
 gpu                        | 0                   
 include_item_features      | 1                   
 include_situation_features | 1                   
 include_user_features      | 0                   
 l2                         | 1e-06               
 loss_n                     | BCE                 
 lr                         | 0.002               
 main_metric                |                     
 mlp1_batch_norm            | 1                   
 mlp1_dropout               | 0.2                 
 mlp1_hidden_activations    | ReLU                
 mlp1_hidden_units          | [64]                
 mlp2_batch_norm            | 1                   
 mlp2_dropout               | 0.5                 
 mlp2_hidden_activations    | ReLU                
 mlp2_hidden_units          | [64,64]             
 num_heads                  | 1                   
 num_neg                    | 0                   
 num_workers                | 1                   
 optimizer                  | Adam                
 random_seed                | 0                   
 save_final_results         | 1                   
 test_all                   | 0                   
 topk                       | 5,10,20,50          
 use_fs                     | 1                   
===================================================
INFO:root:Device: cpu
INFO:root:Load corpus from ../data/ML_1MCTR/ContextReader_context101.pkl
INFO:root:#params: 1302594
INFO:root:FinalMLPCTR(
  (loss_fn): BCELoss()
  (embedding_dict): ModuleDict(
    (i_genre_c): Embedding(298, 64)
    (i_title_c): Embedding(3126, 64)
    (c_day_f): Linear(in_features=1, out_features=64, bias=False)
    (c_hour_c): Embedding(24, 64)
    (c_period_c): Embedding(9, 64)
    (c_weekday_c): Embedding(7, 64)
    (user_id): Embedding(6035, 64)
    (item_id): Embedding(3126, 64)
  )
  (mlp1): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
    )
  )
  (mlp2): MLP_Block(
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=64, bias=True)
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
    )
  )
  (fs_module): FeatureSelection(
    (fs1_ctx_emb): ModuleList(
      (0): Embedding(24, 64)
      (1): Embedding(7, 64)
      (2): Embedding(9, 64)
      (3): Linear(in_features=1, out_features=64, bias=True)
    )
    (fs2_ctx_emb): ModuleList(
      (0): Embedding(298, 64)
      (1): Embedding(3126, 64)
    )
    (fs1_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
    (fs2_gate): MLP_Block(
      (mlp): Sequential(
        (0): Linear(in_features=128, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=64, bias=True)
        (3): ReLU()
        (4): Linear(in_features=64, out_features=512, bias=True)
        (5): Sigmoid()
      )
    )
  )
  (fusion_module): InteractionAggregation(
    (w_x): Linear(in_features=64, out_features=1, bias=True)
    (w_y): Linear(in_features=64, out_features=1, bias=True)
  )
)
INFO:root:Test Before Training: (AUC@All:0.4936,LOG_LOSS@All:0.6931)
INFO:root:Optimizer: Adam
